ALSO
make the shift to the apis, allow an api mode

IF GENERAL INFERENCE IS NOT SUFFICIENT, EXTEND IT OR MAKE A NEW API OR SMTH
MAINTAIN A PERSISTENT CONNECTION BETWEEN API AND LOCAL_VLM AND ALLOW ALL TOOL CALLING AND ALL FEATURES TO THE API

only difference will be that all inferences wil happen on api instead of locally



