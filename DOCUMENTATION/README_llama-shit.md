# Llama-shit

## General Purpose
Experimental directory for LLM inference optimizations using llama.cpp and Qwen model bindings for efficient local execution.

## Files

### `llama.cpp/`
Clone of llama.cpp repository for efficient CPU/GPU inference of large language models using quantized GGUF formats.

### `qwen3vl_bindings/`
Python bindings and interface code for Qwen3-VL vision-language model integration with llama.cpp backend.

### `qwen_mtmd/`
Qwen multi-modal multi-task definitions and configurations for handling various vision-language tasks.

### `export`
Script or utility for exporting/converting models to formats compatible with llama.cpp (GGUF).
